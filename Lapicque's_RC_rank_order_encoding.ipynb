{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP+fToCgFKBxBxJTcdqw1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k1151msarandega/Lapicque-s-RC/blob/main/Lapicque's_RC_rank_order_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Architecture:** *Lapicque's RC*\n",
        "\n",
        "**Encoding Scheme:** *Rank-order encoding*"
      ],
      "metadata": {
        "id": "qQYWE_QwQ4o0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ9AWHdKdTbb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from snntorch import spikegen, surrogate, encoding, data\n",
        "from snntorch import snn\n",
        "from snntorch import utils\n",
        "from snntorch import models\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Set the device"
      ],
      "metadata": {
        "id": "K14Hc4cZdawq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uBYO6q8adpWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the rank-order encoder"
      ],
      "metadata": {
        "id": "yUOJRQ75dt1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = encoding.RankOrderEncoder()"
      ],
      "metadata": {
        "id": "KwwUZVXfdyrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define the Lapicque's RC model"
      ],
      "metadata": {
        "id": "N1mKznipd7Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LapicqueRCModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LapicqueRCModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YtSM9JqAd2Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Load the MNIST dataset"
      ],
      "metadata": {
        "id": "rgrlClZCeEr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "8IUpbS6beaCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create model instance"
      ],
      "metadata": {
        "id": "SyQu_3Abe32u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LapicqueRCModel().to(device)"
      ],
      "metadata": {
        "id": "1ENEWKA_e6K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define the spike generation function"
      ],
      "metadata": {
        "id": "1aXqzy8Ae7Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spike_fn = spikegen.probability"
      ],
      "metadata": {
        "id": "fR1EhKRJe-qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Define the surrogate gradient function"
      ],
      "metadata": {
        "id": "rlvvPbszfBkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "surrogate_fn = surrogate.Sigmoid()"
      ],
      "metadata": {
        "id": "BaDnxeqUfE7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Define the optimizer and loss function"
      ],
      "metadata": {
        "id": "kM07v_xDfHgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0KLuBXS3fOiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Define the SNN optimizer"
      ],
      "metadata": {
        "id": "n2zfFtyXfV9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snn_optimizer = snn.Adam(model, optimizer)"
      ],
      "metadata": {
        "id": "pw4J5_RwfadQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Train the SNN"
      ],
      "metadata": {
        "id": "pB60abYSfdyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    utils.reset_layerwise_stats(model)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Reset the spike accumulator\n",
        "        model.zero_spike_accumulator()\n",
        "\n",
        "        # Encode the input spikes\n",
        "        input_spikes = encoder(data, time=0.5)\n",
        "\n",
        "        # Run the SNN\n",
        "        output_spikes = model(input_spikes)\n",
        "\n",
        "        # Compute the spike gradients and update the model parameters\n",
        "        snn_optimizer.step(output_spikes, target)\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Epoch: {} [{}/{} ({:.0f}%)]'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader)))\n"
      ],
      "metadata": {
        "id": "qKA3wfqxfiNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Testing"
      ],
      "metadata": {
        "id": "HKRv_U-lfqnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            input_spikes = encoder(data, time=0.5)\n",
        "            output_spikes = model(input_spikes)\n",
        "            _, predicted = output_spikes.max(1)\n",
        "            correct += predicted.eq(target).sum().item()"
      ],
      "metadata": {
        "id": "jGJth_cBfvpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Evaluation metrics"
      ],
      "metadata": {
        "id": "5Tb9Eob2f1W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 100. * correct / len(test_loader.dataset)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy))\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print('Execution Time: {:.2f} seconds'.format(execution_time))"
      ],
      "metadata": {
        "id": "LohGFjNOf4Y1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}